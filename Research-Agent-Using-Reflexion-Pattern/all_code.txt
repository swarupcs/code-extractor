

==============================
FILE: E:\Web Dev Course\Coder's Gyan Gen AI Course\Research-Agent-Using-Reflexion-Pattern\src\graph.ts
==============================

import { AIMessage } from '@langchain/core/messages';

import { StateGraph } from '@langchain/langgraph';
import { graphState, questionAnswerSchema } from './state';
import { llm } from './model';
import { searchExecutor } from './tools';


async function responder(state: typeof graphState.State) {
  const currentDateTime = new Date().toLocaleString('sv-SE');

  const SYSTEM_PROMPT = `You are an expert researcher.
Current time: ${currentDateTime}

1. Provide a detailed ~250 word answer.
2. Reflect and critique your answer. Be severe to maximize improvement.
3. Recommend max 3 search queries to research information and improve your answer.`;

  const llmWithStructure = llm.withStructuredOutput(questionAnswerSchema);

  const response = await llmWithStructure.invoke([
    {
      role: 'system',
      content: SYSTEM_PROMPT,
    },
    ...state.messages,
    {
      role: 'system',
      content: `Reflect on the user's original question and the actions taken thus far. Respond using structured output.`,
    },
  ]);

  return {
    messages: [new AIMessage(JSON.stringify(response))],
    iteration: 0,
  };
}

async function revisor(state: typeof graphState.State) {
  const currentDateTime = new Date().toLocaleString('sv-SE');

  const SYSTEM_PROMPT = `You are an expert researcher.
Current time: ${currentDateTime}

Your task is to revise your previous answer using the search results provided.

CRITICAL - Answer Format Requirements:
Your "answer" field MUST have this exact structure:

[Main answer content with citations like [1], [2], [3]...]

References:
- [1] https://actual-url-from-search-results.com
- [2] https://another-url-from-search-results.com
- [3] https://third-url-from-search-results.com

Instructions:
1. Write your main answer (~250 words) using information from the search results
2. Use inline citations [1], [2], [3] in your answer text when referencing sources
3. MANDATORY: End your answer field with a "References:" section listing all URLs
4. The References section is PART of the answer field, not a separate field
5. Extract actual URLs from the search results provided in the conversation
6. Use the previous critique to remove superfluous information
7. Recommend max 3 new search queries to research information and improve your answer.

Example answer field format:
JavaScript is evolving rapidly with new features [1]. WebAssembly integration is improving [2].

References:
- [1] https://example.com/js-features
- [2] https://example.com/webassembly`;

  const llmWithStructure = llm.withStructuredOutput(questionAnswerSchema);

  const response = await llmWithStructure.invoke([
    {
      role: 'system',
      content: SYSTEM_PROMPT,
    },
    ...state.messages,
    {
      role: 'system',
      content: `Reflect on the user's original question and the actions taken thus far. Respond using structured output.`,
    },
  ]);

  return {
    messages: [new AIMessage(JSON.stringify(response))],
    iteration: state.iteration + 1,
  };
}

export const graph = new StateGraph(graphState)
  .addNode('responder', responder)
  .addNode('searchExecutor', searchExecutor)
  .addNode('revisor', revisor)

  .addEdge('__start__', 'responder')
  .addEdge('responder', 'searchExecutor')
  .addEdge('searchExecutor', 'revisor')

  .addConditionalEdges(
    'revisor',
    (state: typeof graphState.State) => {
      const MAX_ITERATIONS = 2;

      if (state.iteration >= MAX_ITERATIONS) {
        return '__end__';
      }

      return 'searchExecutor';
    },
    {
      __end__: '__end__',
      searchExecutor: 'searchExecutor',
    },
  );


==============================
FILE: E:\Web Dev Course\Coder's Gyan Gen AI Course\Research-Agent-Using-Reflexion-Pattern\src\index.ts
==============================

import readline from 'node:readline/promises';
import { graph } from './graph';


async function main() {
  const app = graph.compile();

  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
  });

  while (true) {
    const query = await rl.question('You: ');
    if (query === '/bye') break;

    console.log('\nðŸ¤” Thinking...');
    const result = await app.invoke({
      messages: [{ role: 'user', content: query }],
    });

    console.log('='.repeat(80));
    console.log('Final Answer');
    console.log('='.repeat(80));

    const lastMessage = result.messages[result.messages.length - 1].content;

    console.log(JSON.parse(lastMessage as string).answer);
  }

  rl.close();
}

main();


==============================
FILE: E:\Web Dev Course\Coder's Gyan Gen AI Course\Research-Agent-Using-Reflexion-Pattern\src\model.ts
==============================

import { ChatOpenAI } from '@langchain/openai';

export const llm = new ChatOpenAI({
  model: 'gpt-5-nano-2025-08-07',
});


==============================
FILE: E:\Web Dev Course\Coder's Gyan Gen AI Course\Research-Agent-Using-Reflexion-Pattern\src\state.ts
==============================

import { Annotation, MessagesAnnotation } from '@langchain/langgraph';
import z from 'zod';

const reflectionSchema = z.object({
  missing: z.string().describe('Critique of what is missing.'),
  superfluous: z.string().describe('Critique of what is superfluous'),
});

export const questionAnswerSchema = z.object({
  answer: z.string().describe('~250 word detailed answer to the question.'),
  reflection: reflectionSchema,
  searchQueries: z
    .array(z.string())
    .describe(
      '1-3 search queries for researching improvements to address the critique of your current answer.',
    ),
});

export type QuestionAnswer = z.infer<typeof questionAnswerSchema>;

export const graphState = Annotation.Root({
  ...MessagesAnnotation.spec,
  iteration: Annotation<number>,
});


==============================
FILE: E:\Web Dev Course\Coder's Gyan Gen AI Course\Research-Agent-Using-Reflexion-Pattern\src\tools.ts
==============================

import { HumanMessage, type AIMessage } from '@langchain/core/messages';
import type { graphState, QuestionAnswer } from './state';
import { TavilySearch } from '@langchain/tavily';

const tavilySearch = new TavilySearch({ maxResults: 2 });

export async function searchExecutor(state: typeof graphState.State) {
  const lastMessage = state.messages[state.messages.length - 1] as AIMessage;
  const parsed = JSON.parse(lastMessage.content as string) as QuestionAnswer;

  const searchResult = await tavilySearch.batch(
    parsed.searchQueries.map((query) => ({ query })),
  );

  const cleanedResults = [];

  for (let i = 0; i < parsed.searchQueries.length; i++) {
    const query = parsed.searchQueries[i];
    const searchOutput = searchResult[i];

    // Access the results array directly from the search output
    const results = searchOutput?.results || [];

    // Extract only essential fields from each result
    for (const result of results) {
      cleanedResults.push({
        query: query,
        content: result.content || '',
        url: result.url || '',
      });
    }
  }

  return {
    messages: [
      new HumanMessage(JSON.stringify({ searchResults: cleanedResults })),
    ],
  };
}
